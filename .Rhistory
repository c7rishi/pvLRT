} %>%
data.matrix() %>%
data.table::as.data.table(
keep.rownames = TRUE
) %>%
data.table::setnames(
old = "rn",
new = "AE"
) %>%
data.table::melt(
id.vars = "AE",
variable.name = "Drug",
value.name = measure
)
}
)
tab_lrstat_pval
tab_lrstat_pval <-
c("lrstat", "p.value") %>%
lapply(
function(measure) {
object %>%
{
if (measure == "p.value") {
`class<-`(., "matrix")
} else {
attr(., "lrstat")
}
} %>%
data.matrix() %>%
data.table::as.data.table(
keep.rownames = TRUE
) %>%
data.table::setnames(
old = "rn",
new = "AE"
) %>%
data.table::melt(
id.vars = "AE",
variable.name = "Drug",
value.name = measure
)
}
) %>%
Reduce(
function(dt1, dt2) {
merge(dt1, dt2, by = c("AE", "Drug"))
},
.
)
tab_lrstat_pval
library(pvLRT)
summary(test1)
extract_zi_probability(test1)
extract_significant_pairs(test1)
#' @export
extract_significant_pairs <- function(object, significance_level = 0.05, ...) {
if (!is.pvlrt(object)) {
stop("object must be a 'pvlrt' object.")
}
p.value <- NULL
out <- summary(object)[p.value < significance_level]
out
}
rm(extract_significant_pairs)
library(pvLRT)
extract_significant_pairs(test1)
library(pvLRT)
extract_significant_pairs(test1)
summary(object)
significance_level
summary(object)[p.value < significance_level, ]
summary(object)[p.value > significance_level, ]
rm(p.value)
out <- summary(object)[p.value > significance_level, ]
summary(object)
out <- summary(object)[p.value > significance_level, ]
rm(list=ls())
library(pvLRT)
test1 <- lrt_zi_poisson(lovastatin)
nm <- c("Saptarshi Chakraborty1*, Brett L. Ecker2*, Ken Seier1, Victoria G. Aveson2, Vinod P. Balachandran2,3, Jeffrey A. Drebin2, Michael I. D'Angelica2, T. Peter Kingham2, Carlie S. Sigel4, Kevin C. Soares2, Efsevia Vakiani4,5, Alice C Wei2, Rohit Chandwani6,7, Mithat Gonen1^, Ronglai Shen1^, William R. Jarnagin2^")
library(tidyverse)
nm %>%
strsplit("\\,")
nm %>%
strsplit("\\,") %>%
unlist()
nm %>%
strsplit("\\,") %>%
unlist() %>%
str_remove("\\d")
nm %>%
strsplit("\\,") %>%
unlist() %>%
str_remove("\\d") %>%
str_trim()
nm %>%
strsplit("\\,") %>%
unlist() %>%
str_remove("\\d") %>%
str_trim() %>%
.[. != ""]
xx = "Michael I. D'Angelica"
xx %>%
strsplit(" ") %>%
imap(
function(yy, idx) {
if(idx > 1) {
yy
} else {
substr(yy, 1, 1)
}
}
)
xx %>%
strsplit(" ")
xx %>%
strsplit(" ")
nn <- length(yy)
surname <- yy[nn]
xx
xx %>%
strsplit(" ")
xx %>%
strsplit(" ") %>%
unlist()
nn <- length(yy)
yy <- xx %>%
strsplit(" ") %>%
unlist()
nn <- length(yy)
surname <- yy[nn]
nn
surname
firstinit
firstinit <- yy[-nn] %>%
sapply(substr, start = 1, stop = 1)
firstinit
yy[-nn] %>%
sapply(substr, start = 1, stop = 1) %>%
paste("\\.")
paste(collapse = " ")
firstinit <- yy[-nn] %>%
sapply(substr, start = 1, stop = 1) %>%
paste0("\\.") %>%
paste(collapse = " ")
if(idx ) {
yy
} else {
substr(yy, 1, 1)
}
firstinit
firstinit <- yy[-nn] %>%
sapply(substr, start = 1, stop = 1) %>%
paste0(".") %>%
paste(collapse = " ")
firstinit
glue::glue("{surname}, {firstinit}")
nm %>%
strsplit("\\,") %>%
unlist() %>%
str_remove("\\d") %>%
str_trim() %>%
.[. != ""] %>%
sapply(
function(xx) {
yy <- xx %>%
strsplit(" ") %>%
unlist()
nn <- length(yy)
surname <- yy[nn]
firstinit <- yy[-nn] %>%
sapply(substr, start = 1, stop = 1) %>%
paste0(".") %>%
paste(collapse = " ")
glue::glue("{surname}, {firstinit}")
}
) %>%
paste(collapse = ", ")
nm %>%
strsplit("\\,") %>%
unlist() %>%
str_remove("\\d") %>%
str_trim() %>%
.[. != ""] %>%
str_remove("\\^|\\*")
nm %>%
strsplit("\\,") %>%
unlist() %>%
str_remove("\\d") %>%
str_trim() %>%
.[. != ""] %>%
str_remove("\\^|\\*") %>%
sapply(
function(xx) {
yy <- xx %>%
strsplit(" ") %>%
unlist()
nn <- length(yy)
surname <- yy[nn]
firstinit <- yy[-nn] %>%
sapply(substr, start = 1, stop = 1) %>%
paste0(".") %>%
paste(collapse = " ")
glue::glue("{surname}, {firstinit}")
}
) %>%
paste(collapse = ", ")
nm %>%
strsplit("\\,") %>%
unlist() %>%
str_remove("\\d") %>%
str_trim() %>%
.[. != ""] %>%
str_remove("\\^|\\*") %>%
sapply(
function(xx) {
yy <- xx %>%
strsplit(" ") %>%
unlist()
nn <- length(yy)
surname <- yy[nn]
firstinit <- yy[-nn] %>%
sapply(substr, start = 1, stop = 1) %>%
paste0(".") %>%
paste(collapse = " ")
glue::glue("{surname}, {firstinit}")
}
) %>%
paste(collapse = ", ") %>%
cat()
library(pvLRT)
?lrt_zi_poisson
# use gamma prior assumption on signals while
# estimating omegas
test3 <- lrt_zi_poisson(
statin1491
)
test3
test3
summary(test3)
?plot
library(pvLRT)
library(pvLRT)
install.packages("pheatmap")
library(pvLRT)
library(pvLRT)
library(pvLRT)
plot(cars)
library(pvLRT)
?lrt_zi_poisson
data("lovastatin")
test1 <- lrt_zi_poisson(lovastatin)
test1
library(pvLRT)
library(tidyverse)
library(pvLRT)
meths <- list(
lambda_lrt = lrt_poisson,
pseudo_lambda_lrt = pvlrt
)
res_list <- list(
lambda_lrt = lrt_poisson,
pseudo_lambda_lrt = pvlrt
) %>%
lapply(
function(this_fn) {
this_fn(dat)
}
)
dat <- statin
set.seed(100)
res_list <- list(
lambda_lrt = lrt_poisson,
pseudo_lambda_lrt = pvlrt
) %>%
lapply(
function(this_fn) {
this_fn(dat)
}
)
barplot(res_list$lambda_lrt, p.value_upper = 0.05)
?data.table::setnames
source("D:/Documents/GitHub/pvLRT/R/pvlrt-postprocessing-utils.R")
saveRDS(res_list, "~/results_pvlrt_statin6039.RDS")
rm(list = ls())
?missingArg
library(pvLRT)
library(pvLRT)
?set_AE_names
library(tidyverse)
library(pvLRT)
set.seed(100)
dat <- statin46
res_list <- list(
lambda_lrt = lrt_poisson,
pseudo_lambda_lrt = pvlrt
) %>%
lapply(
function(this_fn) {
this_fn(dat)
}
)
res_list$lambda_lrt %>% summary()
res_list$lambda_lrt
extract_lrstat_matrix(res_list$lambda_lrt)
extract_pvalue_matrix(res_list$lambda_lrt)
library(pvLRT)
res_list$lambda_lrt
res_list$lambda_lrt
tmp = res_list$lambda_lrt
tmp1 = set_AE_names(tmp)
tmp1 = set_AE_names(tmp, old = "atorvastatin", new = "Atorvastatin")
tmp1
dimnames(tmp1)
tmp1 = set_Drug_names(tmp, old = "atorvastatin", new = "Atorvastatin")
tmp1
tmp1 = tmp %>% set_Drug_names(old = extract_Drug_names(.), new = toupper(extract_Drug_names(.)))
tmp1
library(pvLRT)
extract_pvalue_matrix(tmp1)
attributes(tmp1) %>% names()
attributes(tmp1) %>% names() %>% dput()
library(pvLRT)
extract_pvalue_matrix(tmp1)
library(pvLRT)
install.packages("testthat")
library(pvLRT)
library(BAMBI)
?fit_vmsinmix
# illustration only - more iterations needed for convergence
fit.vmsin.20 <- fit_vmsinmix(tim8, ncomp = 3, n.iter =  200,
n.chains = 1)
fit.vmsin.20
contour(fit.vmsin.20)
contour(fit.vmsin.20, xlab = "x")
contour.angmix
BAMBI:::contour.angmix
BAMBI:::contour.angmcmc
fit.vmsin.20$data <- colnames("ϕ", "ψ")
colnames(fit.vmsin.20$data) <- c("ϕ", "ψ")
contour(fit.vmsin.20)
colnames(fit.vmsin.20$data) <- c(bquote(phi), bquote(psi))
contour(fit.vmsin.20)
colnames(fit.vmsin.20$data) <- c("ϕ", "ψ")
contour(fit.vmsin.20)
news
news()
pdf("~/tmp.pdf")
contour(fit.vmsin.20)
dev.off
dev.off()
cairo_pdf("~/tmp.pdf")
contour(fit.vmsin.20)
dev.off()
BAMBI:::contour.angmcmc
View(BAMBI:::contour.angmcmc)
library(pvLRT)
install.packages("stylr")
install.packages("styler")
styler:::style_active_file()
styler:::style_active_pkg()
?heatmap_pvlrt
library(pvLRT)
?heatmap_pvlrt
source("C:/Users/chakrab2/Documents/GitHub/pvLRT/R/pvlrt-plots.R")
rm(list=ls())
keras::install_keras()
install.packages("rstanarm")
?rstanarm::stan_glm
### Linear regression
mtcars$mpg10 <- mtcars$mpg / 10
fit <- stan_glm(
mpg10 ~ wt + cyl + am,
data = mtcars,
QR = TRUE,
# for speed of example only (default is "sampling")
algorithm = "fullrank",
refresh = 0
)
library(rstanarm)
### Linear regression
mtcars$mpg10 <- mtcars$mpg / 10
fit <- stan_glm(
mpg10 ~ wt + cyl + am,
data = mtcars,
QR = TRUE,
# for speed of example only (default is "sampling")
algorithm = "fullrank",
refresh = 0
)
fit
### Linear regression
mtcars$mpg10 <- mtcars$mpg / 10
fit <- stan_glm(
mpg10 ~ wt + cyl + am,
data = mtcars,
QR = TRUE,
# for speed of example only (default is "sampling")
algorithm = "sampling",
refresh = 0
)
fit
head(wells)
wells$dist100 <- wells$dist / 100
fit2 <- stan_glm(
switch ~ dist100 + arsenic,
data = wells,
family = binomial(link = "logit"),
prior_intercept = normal(0, 10),
QR = TRUE,
refresh = 0,
# for speed of example only
#chains = 4, iter = 200
)
fit2
?keras::keras
library(keras)
# Set parameters:
max_features <- 5000
maxlen <- 400
batch_size <- 32
embedding_dims <- 50
filters <- 250
kernel_size <- 3
hidden_dims <- 250
epochs <- 2
# ..$ x:List of 25000
# .. .. [list output truncated]
# .. ..- attr(*, "dim")= int 25000
# ..$ y: num [1:25000(1d)] 1 1 1 1 1 0 0 0 1 1 ...
#
# The x data includes integer sequences, each integer is a word.
# The y data includes a set of integer labels (0 or 1).
# The num_words argument indicates that only the max_fetures most frequent
# words will be integerized. All other will be ignored.
# See help(dataset_imdb)
imdb <- dataset_imdb(num_words = max_features)
# Pad the sequences, so they have all the same length
# This will convert the dataset into a matrix: each line is a review
# and each column a word on the sequence.
# Pad the sequences with 0 to the left.
x_train <- imdb$train$x %>%
pad_sequences(maxlen = maxlen)
x_test <- imdb$test$x %>%
pad_sequences(maxlen = maxlen)
#Initialize model
model <- keras_model_sequential()
model %>%
# Start off with an efficient embedding layer which maps
# the vocab indices into embedding_dims dimensions
layer_embedding(max_features, embedding_dims, input_length = maxlen) %>%
layer_dropout(0.2) %>%
# Add a Convolution1D, which will learn filters
# Word group filters of size filter_length:
layer_conv_1d(
filters, kernel_size,
padding = "valid", activation = "relu", strides = 1
) %>%
# Apply max pooling:
layer_global_max_pooling_1d() %>%
# Add a vanilla hidden layer:
layer_dense(hidden_dims) %>%
# Apply 20% layer dropout
layer_dropout(0.2) %>%
layer_activation("relu") %>%
# Project onto a single unit output layer, and squash it with a sigmoid
layer_dense(1) %>%
layer_activation("sigmoid")
# Compile model
model %>% compile(
loss = "binary_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
model %>%
fit(
x_train, imdb$train$y,
batch_size = batch_size,
epochs = epochs,
validation_data = list(x_test, imdb$test$y)
)
class(model)
ls()
library(pvLRT)
library(pvLRT)
?lrt_zi_poisson
data("lovastatin")
test1 <- lrt_zi_poisson(lovastatin)
test1
plot(test1)
heatmap_pvlrt(test1)
barplot(test1)
library(pvLRT)
barplot(test1)
heatmap_pvlrt(test1)
barplot(test1)
extract_lrstat_matrix(test1)
as.matrix(test1)
library(pvLRT)
as.matrix(test1)
1
object1 <- object
attributes(object) <- attributes(
object
)[c("dim", "dimnames", "class")]
object1 <- object
attributes(object) <- attributes(
object
)[c("dim", "dimnames", "class")]
as.matrix(object)
1
